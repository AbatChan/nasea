# NASEA Configuration
# Copy this file to .env and fill in your actual values

# ============================================
# LLM API Keys (choose one or both for fallback)
# ============================================

# Kimi K2 API Key (Primary - cost-effective)
# Get your key from: https://platform.moonshot.cn/
KIMI_API_KEY=your_kimi_api_key_here

# OpenAI API Key (Fallback - more reliable)
# Get your key from: https://platform.openai.com/
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic Claude API Key (Optional - for advanced features)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# ============================================
# Model Configuration
# ============================================

# Primary model to use: kimi-k2, gpt-4-turbo, gpt-4, claude-3-sonnet
DEFAULT_MODEL=kimi-k2

# Fallback model if primary fails
FALLBACK_MODEL=gpt-4-turbo

# Lightweight intent/chat model (for understanding quick prompts)
INTENT_MODEL=venice-uncensored

# Model temperature (0.0 = deterministic, 1.0 = creative)
TEMPERATURE=0.7

# Max tokens per request
MAX_TOKENS=4096

# ============================================
# Generation Settings
# ============================================

# Maximum refinement iterations if tests fail
MAX_ITERATIONS=3

# Maximum file size in lines
MAX_FILE_SIZE=10000

# Maximum files per project
MAX_FILES=50

# Timeout for code execution (seconds)
EXECUTION_TIMEOUT=60

# ============================================
# Output Configuration
# ============================================

# Where to save generated projects
OUTPUT_DIR=./output

# Create timestamped folders for each generation
USE_TIMESTAMPS=true

# Save intermediate results for debugging
SAVE_INTERMEDIATE=false

# ============================================
# Logging
# ============================================

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Log file path
LOG_FILE=./nasea.log

# Enable console logging
CONSOLE_LOGGING=true

# Console log level for CLI output (INFO, WARNING, ERROR)
CONSOLE_LOG_LEVEL=WARNING

# ============================================
# Testing & Verification
# ============================================

# Enable automatic test generation
AUTO_GENERATE_TESTS=true

# Run static analysis on generated code
RUN_STATIC_ANALYSIS=true

# Run security scanning
RUN_SECURITY_SCAN=true

# Minimum test coverage required (%)
MIN_COVERAGE=70

# ============================================
# Memory & Caching
# ============================================

# Enable response caching to reduce API costs
ENABLE_CACHING=true

# Cache directory
CACHE_DIR=./.cache

# Cache TTL in seconds (86400 = 24 hours)
CACHE_TTL=86400

# Session state tracking (reduces redundant file reads and token waste)
# "auto"   = enable after 3+ files touched (recommended)
# "always" = always enable (for complex projects)
# "never"  = disable (for simple one-shot tasks)
SESSION_TRACKING=auto

# ============================================
# Advanced Settings
# ============================================

# Enable debug mode (verbose logging)
DEBUG_MODE=false

# Use Docker for code execution sandboxing
USE_DOCKER_SANDBOX=false

# Enable web UI (Phase 2 feature)
ENABLE_WEB_UI=false

# API rate limiting (requests per minute)
RATE_LIMIT=20

# ============================================
# Database (for persistent memory)
# ============================================

# Database path for context storage
DATABASE_PATH=./nasea.db

# Vector database collection name
VECTOR_COLLECTION=nasea_memory

# ============================================
# Privacy & Security
# ============================================

# Redact sensitive information from logs
REDACT_LOGS=true

# Disable telemetry (always off by default)
TELEMETRY_ENABLED=false
